{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction! Thank you for purchasing this software, I really appreciate your support. To get started you first will need to have docker running on your machine, you can get install steps here : https://docs.docker.com/engine/install/ It is possible to run this project without docker on linux and Mac OS by simply installing python 3 and PHP 7+. You will also need CURL installed on your system and as well as the php curl extension. Below is a list of suggested php extensions to install if you are running this project without docker: bcmath curl zip mbstring dom For python, you will need python 3+ and fasttext: pip install fasttext Who is this project for? The purpose of this project is to provide a minimal template for your machine learning projects, while working on a few classification projects - I found that getting the data and generating input data for my models where very painful. Being a software engineer and not a data scientist, I found it pretty cumbersome to find resources on the topic that are not geared towards data scienctists - while it's great to learn some statistics - as a programmer, I'm used to importing a class/library and working with an API rather than focusing on plotting graphs and working with jupyter notebooks. This project is targeted towards programers who want to use machine learning in their software but are not necessarily interested in deep diving into data science topics. Project layout userguide/ # Documentation for this project. mltoolkit/ # Here you will find all the Python code needed to generate Fasttext models. classifier.py # All the functions needed to generate models and predictions. test.py # An example of how to use the train, load model and predict functions. scrapers/ # Implementations of PHP scrapers. Shopify.php # A scraper that will allow you to scrape most shopify stores. Toscraper.php # An example scraper of how to handle HTML DOM elements. Core/ # Provides some basic functionality such as crawling http links. Scraper.php # A base class for all scrapers. console.php # A CLI tool to run scrapers similar to laravel's \"artisan\" tool. models/ # Will contain .bin and .txt files generated for fasttext models. composer.phar # C Configuring scrapers In the project root you will find a config.json file, which contains a list of scraper configuration nodes. Each scraper configuration should contain a definition similar to the following: { \"name\": \"myawesomeshopifyexamplestore.com\", // this is the name used when running the scraper \"class\": \"Shopify\", // PHP class name as found in the scrapers folder. \"feed_path\": \"./feeds/myawesomeshopifyexamplestore.json\", // Where to store the scraped data. \"base_url\": \"https:www.myawesomeshopifyexamplestore.co/\", // The URL to scrape. \"description\": \"A sample scrapper that scrapes shopify products\", \"classifier\": { \"feed_path\": \"../feeds/myawesomeshopifyexamplestore.json\", // Same as feed_path above \"model_path\": \"../models/myawesomeshopifyexamplestore.bin\", // Where to save the compiled model. // Where to store the dataset formatted from the scraped data. \"dataset_path\": \"../models/datasets/myawesomeshopifyexamplestore.txt\", \"field\": \"category\", // The field from the scraped data to use as a category label. \"text\": \"title\", // The field to use as text training data. // Fasttext configuration's - learn more here: // https://fasttext.cc/docs/en/options.html \"loss_function\": \"ova\", \"epochs\": 25, \"ngrams\": 2, \"threads\": 30 } } Setting up docker To get a container up and running with Python and PHP dependencies - there is a \"Dockerfile\" in the project root directory - you can build and run the docker container as follows: Setting up the container: docker build . -t mltoolkit docker run --name mltoolkit -dit --rm -v ${PWD}:/app mltoolkit /bin/bash docker exec -it mltoolkit composer install Note: Once you've built the container, you do not need to re-run all the above each time, simply run this whenever you want to start the container: docker run --name mltoolkit -dit --rm -v ${PWD}:/app mltoolkit /bin/bash Get a list of scrapers: docker exec -it mltoolkit php console.php Run individual scraper: docker exec -it mltoolkit php console.php toscraper Run python model train, load and predict test: docker exec -it mltoolkit bash -c \"cd /app/mltoolkit && python3 test.py\" Good luck! All the best in your building journey, I hope that this project will be useful and save you a ton of time. I have tried my best to document as much as possible, including comments in the code however should you run into any trouble - please feel free to send your questions through to : support@plexcorp.tech","title":"Introduction!"},{"location":"#introduction","text":"Thank you for purchasing this software, I really appreciate your support. To get started you first will need to have docker running on your machine, you can get install steps here : https://docs.docker.com/engine/install/ It is possible to run this project without docker on linux and Mac OS by simply installing python 3 and PHP 7+. You will also need CURL installed on your system and as well as the php curl extension. Below is a list of suggested php extensions to install if you are running this project without docker: bcmath curl zip mbstring dom For python, you will need python 3+ and fasttext: pip install fasttext","title":"Introduction!"},{"location":"#who-is-this-project-for","text":"The purpose of this project is to provide a minimal template for your machine learning projects, while working on a few classification projects - I found that getting the data and generating input data for my models where very painful. Being a software engineer and not a data scientist, I found it pretty cumbersome to find resources on the topic that are not geared towards data scienctists - while it's great to learn some statistics - as a programmer, I'm used to importing a class/library and working with an API rather than focusing on plotting graphs and working with jupyter notebooks. This project is targeted towards programers who want to use machine learning in their software but are not necessarily interested in deep diving into data science topics.","title":"Who is this project for?"},{"location":"#project-layout","text":"userguide/ # Documentation for this project. mltoolkit/ # Here you will find all the Python code needed to generate Fasttext models. classifier.py # All the functions needed to generate models and predictions. test.py # An example of how to use the train, load model and predict functions. scrapers/ # Implementations of PHP scrapers. Shopify.php # A scraper that will allow you to scrape most shopify stores. Toscraper.php # An example scraper of how to handle HTML DOM elements. Core/ # Provides some basic functionality such as crawling http links. Scraper.php # A base class for all scrapers. console.php # A CLI tool to run scrapers similar to laravel's \"artisan\" tool. models/ # Will contain .bin and .txt files generated for fasttext models. composer.phar # C","title":"Project layout"},{"location":"#configuring-scrapers","text":"In the project root you will find a config.json file, which contains a list of scraper configuration nodes. Each scraper configuration should contain a definition similar to the following: { \"name\": \"myawesomeshopifyexamplestore.com\", // this is the name used when running the scraper \"class\": \"Shopify\", // PHP class name as found in the scrapers folder. \"feed_path\": \"./feeds/myawesomeshopifyexamplestore.json\", // Where to store the scraped data. \"base_url\": \"https:www.myawesomeshopifyexamplestore.co/\", // The URL to scrape. \"description\": \"A sample scrapper that scrapes shopify products\", \"classifier\": { \"feed_path\": \"../feeds/myawesomeshopifyexamplestore.json\", // Same as feed_path above \"model_path\": \"../models/myawesomeshopifyexamplestore.bin\", // Where to save the compiled model. // Where to store the dataset formatted from the scraped data. \"dataset_path\": \"../models/datasets/myawesomeshopifyexamplestore.txt\", \"field\": \"category\", // The field from the scraped data to use as a category label. \"text\": \"title\", // The field to use as text training data. // Fasttext configuration's - learn more here: // https://fasttext.cc/docs/en/options.html \"loss_function\": \"ova\", \"epochs\": 25, \"ngrams\": 2, \"threads\": 30 } }","title":"Configuring scrapers"},{"location":"#setting-up-docker","text":"To get a container up and running with Python and PHP dependencies - there is a \"Dockerfile\" in the project root directory - you can build and run the docker container as follows: Setting up the container: docker build . -t mltoolkit docker run --name mltoolkit -dit --rm -v ${PWD}:/app mltoolkit /bin/bash docker exec -it mltoolkit composer install Note: Once you've built the container, you do not need to re-run all the above each time, simply run this whenever you want to start the container: docker run --name mltoolkit -dit --rm -v ${PWD}:/app mltoolkit /bin/bash Get a list of scrapers: docker exec -it mltoolkit php console.php Run individual scraper: docker exec -it mltoolkit php console.php toscraper Run python model train, load and predict test: docker exec -it mltoolkit bash -c \"cd /app/mltoolkit && python3 test.py\"","title":"Setting up docker"},{"location":"#good-luck","text":"All the best in your building journey, I hope that this project will be useful and save you a ton of time. I have tried my best to document as much as possible, including comments in the code however should you run into any trouble - please feel free to send your questions through to : support@plexcorp.tech","title":"Good luck!"}]}